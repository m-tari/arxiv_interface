#!/usr/bin/env python
# coding: utf-8

# # Automatic tagging

# ## Modelling

# The goal of this section is to build a system that detects the category of an article based on the abstract. To achieve our goal, we need to use the processed text data from the last section to build a machine learning model. First we load the 20k sample dataset:

# In[1]:


import pandas as pd
import os, sys
import joblib


# In[10]:


df_20k = pd.read_csv('../input/arxiv_20krows_train.csv', converters={'general_category': pd.eval}) # read general category and make sure it is loaded as a list


# In[32]:


df_20k.head()


# ## Model selection

# Since machine learning models only accept numbers as an input, we need to convert words to numbers. There are many techniques for this task, and one of the simplest ones is to make a vector of abstract using **TF-IDF** method. The numeric representation of each word is proportional to frequency of the word in documents ([more about TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf)).

# When abstracts are converted to numbers, we feed the the `abstract` as features and `general_category` as labels to the model for training. A simple model that is frequently use for text classification is Naive Bayes model. The Naive Bayes models predicts the category of an article based on prior knowledge of features of a class in training data. The limitation of Naive Bayes model is that is assumes features (in our case words) are not correlated, which might not be true for many cases. Despite this limitation, Naive Bayes is fast and can be used as strong base model.

# ## Evaluation

# In order to evaluate the performance of our model, we need to select a suitable metric. In a classification problem, accuracy, precision and recall are the most common metrics. Since our dataset is imbalanced, accuracy will not be a good choice to measure the performance. Our goal is to accurately identify a label in our predictions (high precision), and also we want to identify most of the samples of a label (high recall). So we select f1-score as our metric, since it is a harmonic mean of the two previous metrics.

# So the steps for the model training are:
#     
# 1. Convert labels (`general_category`) to 0's and 1's
# 2. Convert abstracts to numbers using TF-IDF
# 3. Fit the model on training data
# 4. Predict the f1-score on test data to calculate the evaluation metric

# To get a better picture of model performance, we use K-fold validation technique to split training dataset into k parts. Then we repeat the above process for each fold of the dataset.

# The above steps are implemented in `train.py` script in `src` directory.

# Let's train our first model with 3 folds:

# In[4]:


dir_path = os.path.dirname(os.getcwd())
SRC_PATH = os.path.join(dir_path, "src")

if SRC_PATH not in sys.path:
    sys.path.append(SRC_PATH)


# In[5]:


import train, config_set
from train import train_model


# In[34]:


train_model(3, 'n_bayes') 


# The f1-score is around 0.31 which is not great. There are a few reasons that the performance is poor:
# - Number of samples for each category is not enough. (e.g category 3, 6, 12 and 16)
# - The features generated by TF-IDF technique are not a good representative of each category. There is a need for more elaborate feature engineering.
# - The Naive Bayes model is a simple model that is not powerful to make good predictions

# To overcome the first reason, we load the second dataset with 100k samples, so there are more samples for each category. We postpone feature engineering of the TF-IDF technique to a later time, and we use more powerful transformer models in next section to compare the performance of newer models to Naive Bayes,

# So now let's load the second dataset.

# In[2]:


sample_df = pd.read_csv('../input/sample_df_2021.csv', converters={'general_category': pd.eval})


# In[3]:


sample_df['general_category'][1]


# In[ ]:


import importlib
importlib.reload(config_set)


# In[8]:


train_model(3, 'n_bayes') 


# It seems that we got a better model since the f1-score improved to 0.47. But still there is room for more improvement. We can continue the model training stage with trying more models, feature engineering, model hyper-parameter optimization, number of features, samples per category, and different word embeddings.

# Finally we save the Naive Base as our baseline model.

# ## Inference

# Let's predict the class of two samples using our model.

# In[46]:


# source: https://arxiv.org/pdf/2112.00728, category:math
Sample1 = '''
we address the problem of reshaping light in the schrödinger optics regime from the
perspective of optimal control theoryN in technological applicationsL schrödinger optics is often
used to model a slowlyMvarying amplitude of a paraMaxially propagating electric field where the
square of the waveguideGs index of refraction is treated as the potentialN the objective of the
optimal control problem is to find the controlling potential whichL together with the constraining
schrödinger dynamicsL optimally reshape the intensity distribution of schrödinger eigenfunctions
from one end of the waveguide to the otherN this work considers reshaping problems found
in work due to kunkel and legerL and addresses computational needs by adopting tools from
the quantum control literatureN the success of the optimal control approach is demonstrated
numerically.
'''

# source: https://arxiv.org/pdf/2112.00746, category:hep-th
Sample2 = '''
We study quantum fields on an arbitrary, rigid background with boundary. We derive
the action for a scalar in the holographic basis that separates the boundary and bulk de-
grees of freedom. From this holographic action, a relation between Dirichlet and Neumann
propagators valid for any background is obtained. As an application in a warped back-
ground, we derive an exact formula for the flux of bulk modes emitted from the boundary.
We also derive the holographic action in the presence of two boundaries. Integrating out
free bulk modes, we derive a formula for the Casimir pressure on a (d−1)-brane depending
only on the boundary-to-bulk propagators. In AdS2 we find that the quantum force pushes
a point particle toward the AdS2 boundary. In higher dimensional AdSd+1 the quantum
pressure amounts to a detuning of the brane tension, which gets renormalized for even d.
We evaluate the one-loop boundary effective action in the presence of interactions by
means of the heat kernel expansion. We integrate out a heavy scalar fluctuation with scalar
interactions in AdSd+1, obtaining the long-distance effective Lagrangian encoding loop-
generated boundary-localized operators. We integrate out nonabelian vector fluctuations
in AdS4,5,6 and obtain the associated holographic Yang-Mills β functions. Turning to the
expanding patch of dS, following recent proposals, we provide a boundary effective action
generating the perturbative cosmological correlators by analytically continuing from dS to
EAdS. We obtain the “cosmological” heat kernel coefficients in the scalar case and work
out the divergent part of the dS4 effective action which renormalizes the cosmological
correlators. More developments are needed to extract all one-loop information from the
cosmological effective action.
'''


# In[39]:


# STEPS
# load model
# load vectorizer
# predict the category


# In[40]:


# loading the trained model and vectorizer
model_bin = open(config.MODEL_OUTPUT_PATH, 'rb') 
classifier = joblib.load(model_bin)

vectorizer_bin = open(config.VECTORIZER_PATH, 'rb') 
vectorizer = joblib.load(vectorizer_bin)


# In[47]:


vectorizer.get_feature_names_out()


# In[48]:


input_str = vectorizer.transform([Sample1, Sample2])


# In[49]:


input_str


# In[50]:


predictions = classifier.predict(input_str)
predictions


# In[52]:


classifier.classes_


# In[51]:


probs=classifier.predict_proba(input_str)
probs


# The classifier predicts none of the categories for the two samples, which in this case might be from poor performance of the trained model.
