{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Automatic tagging"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this section is to build a system that detects the category of an article based on the abstract. To achieve our goal, we need to use the processed text data from the last section to build a machine learning model. First we load the 20k sample dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os, sys\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_20k = pd.read_csv('../input/arxiv_20krows_train.csv', converters={'general_category': pd.eval}) # read general category and make sure it is loaded as a list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>submitter</th>\n",
       "      <th>authors</th>\n",
       "      <th>title</th>\n",
       "      <th>comments</th>\n",
       "      <th>journal-ref</th>\n",
       "      <th>doi</th>\n",
       "      <th>report-no</th>\n",
       "      <th>categories</th>\n",
       "      <th>license</th>\n",
       "      <th>abstract</th>\n",
       "      <th>versions</th>\n",
       "      <th>update_date</th>\n",
       "      <th>authors_parsed</th>\n",
       "      <th>cats_split</th>\n",
       "      <th>general_category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>704.0001</td>\n",
       "      <td>Pavel Nadolsky</td>\n",
       "      <td>C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...</td>\n",
       "      <td>Calculation of prompt diphoton production cros...</td>\n",
       "      <td>37 pages, 15 figures; published version</td>\n",
       "      <td>Phys.Rev.D76:013009,2007</td>\n",
       "      <td>10.1103/PhysRevD.76.013009</td>\n",
       "      <td>ANL-HEP-PR-07-12</td>\n",
       "      <td>hep-ph</td>\n",
       "      <td>NaN</td>\n",
       "      <td>A fully differential calculation in perturba...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Mon, 2 Apr 2007...</td>\n",
       "      <td>2008-11-26</td>\n",
       "      <td>[['Balázs', 'C.', ''], ['Berger', 'E. L.', '']...</td>\n",
       "      <td>['hep-ph']</td>\n",
       "      <td>[hep-ph]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>704.0002</td>\n",
       "      <td>Louis Theran</td>\n",
       "      <td>Ileana Streinu and Louis Theran</td>\n",
       "      <td>Sparsity-certifying Graph Decompositions</td>\n",
       "      <td>To appear in Graphs and Combinatorics</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>math.CO cs.CG</td>\n",
       "      <td>http://arxiv.org/licenses/nonexclusive-distrib...</td>\n",
       "      <td>We describe a new algorithm, the $(k,\\ell)$-...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sat, 31 Mar 200...</td>\n",
       "      <td>2008-12-13</td>\n",
       "      <td>[['Streinu', 'Ileana', ''], ['Theran', 'Louis'...</td>\n",
       "      <td>['math.CO', 'cs.CG']</td>\n",
       "      <td>[math, cs]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>704.0003</td>\n",
       "      <td>Hongjun Pan</td>\n",
       "      <td>Hongjun Pan</td>\n",
       "      <td>The evolution of the Earth-Moon system based o...</td>\n",
       "      <td>23 pages, 3 figures</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>physics.gen-ph</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The evolution of Earth-Moon system is descri...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sun, 1 Apr 2007...</td>\n",
       "      <td>2008-01-13</td>\n",
       "      <td>[['Pan', 'Hongjun', '']]</td>\n",
       "      <td>['physics.gen-ph']</td>\n",
       "      <td>[physics]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>704.0004</td>\n",
       "      <td>David Callan</td>\n",
       "      <td>David Callan</td>\n",
       "      <td>A determinant of Stirling cycle numbers counts...</td>\n",
       "      <td>11 pages</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>math.CO</td>\n",
       "      <td>NaN</td>\n",
       "      <td>We show that a determinant of Stirling cycle...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Sat, 31 Mar 200...</td>\n",
       "      <td>2007-05-23</td>\n",
       "      <td>[['Callan', 'David', '']]</td>\n",
       "      <td>['math.CO']</td>\n",
       "      <td>[math]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>704.0005</td>\n",
       "      <td>Alberto Torchinsky</td>\n",
       "      <td>Wael Abu-Shammala and Alberto Torchinsky</td>\n",
       "      <td>From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Illinois J. Math. 52 (2008) no.2, 681-689</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>math.CA math.FA</td>\n",
       "      <td>NaN</td>\n",
       "      <td>In this paper we show how to compute the $\\L...</td>\n",
       "      <td>[{'version': 'v1', 'created': 'Mon, 2 Apr 2007...</td>\n",
       "      <td>2013-10-15</td>\n",
       "      <td>[['Abu-Shammala', 'Wael', ''], ['Torchinsky', ...</td>\n",
       "      <td>['math.CA', 'math.FA']</td>\n",
       "      <td>[math, math]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id           submitter  \\\n",
       "0  704.0001      Pavel Nadolsky   \n",
       "1  704.0002        Louis Theran   \n",
       "2  704.0003         Hongjun Pan   \n",
       "3  704.0004        David Callan   \n",
       "4  704.0005  Alberto Torchinsky   \n",
       "\n",
       "                                             authors  \\\n",
       "0  C. Bal\\'azs, E. L. Berger, P. M. Nadolsky, C.-...   \n",
       "1                    Ileana Streinu and Louis Theran   \n",
       "2                                        Hongjun Pan   \n",
       "3                                       David Callan   \n",
       "4           Wael Abu-Shammala and Alberto Torchinsky   \n",
       "\n",
       "                                               title  \\\n",
       "0  Calculation of prompt diphoton production cros...   \n",
       "1           Sparsity-certifying Graph Decompositions   \n",
       "2  The evolution of the Earth-Moon system based o...   \n",
       "3  A determinant of Stirling cycle numbers counts...   \n",
       "4  From dyadic $\\Lambda_{\\alpha}$ to $\\Lambda_{\\a...   \n",
       "\n",
       "                                  comments  \\\n",
       "0  37 pages, 15 figures; published version   \n",
       "1    To appear in Graphs and Combinatorics   \n",
       "2                      23 pages, 3 figures   \n",
       "3                                 11 pages   \n",
       "4                                      NaN   \n",
       "\n",
       "                                 journal-ref                         doi  \\\n",
       "0                   Phys.Rev.D76:013009,2007  10.1103/PhysRevD.76.013009   \n",
       "1                                        NaN                         NaN   \n",
       "2                                        NaN                         NaN   \n",
       "3                                        NaN                         NaN   \n",
       "4  Illinois J. Math. 52 (2008) no.2, 681-689                         NaN   \n",
       "\n",
       "          report-no       categories  \\\n",
       "0  ANL-HEP-PR-07-12           hep-ph   \n",
       "1               NaN    math.CO cs.CG   \n",
       "2               NaN   physics.gen-ph   \n",
       "3               NaN          math.CO   \n",
       "4               NaN  math.CA math.FA   \n",
       "\n",
       "                                             license  \\\n",
       "0                                                NaN   \n",
       "1  http://arxiv.org/licenses/nonexclusive-distrib...   \n",
       "2                                                NaN   \n",
       "3                                                NaN   \n",
       "4                                                NaN   \n",
       "\n",
       "                                            abstract  \\\n",
       "0    A fully differential calculation in perturba...   \n",
       "1    We describe a new algorithm, the $(k,\\ell)$-...   \n",
       "2    The evolution of Earth-Moon system is descri...   \n",
       "3    We show that a determinant of Stirling cycle...   \n",
       "4    In this paper we show how to compute the $\\L...   \n",
       "\n",
       "                                            versions update_date  \\\n",
       "0  [{'version': 'v1', 'created': 'Mon, 2 Apr 2007...  2008-11-26   \n",
       "1  [{'version': 'v1', 'created': 'Sat, 31 Mar 200...  2008-12-13   \n",
       "2  [{'version': 'v1', 'created': 'Sun, 1 Apr 2007...  2008-01-13   \n",
       "3  [{'version': 'v1', 'created': 'Sat, 31 Mar 200...  2007-05-23   \n",
       "4  [{'version': 'v1', 'created': 'Mon, 2 Apr 2007...  2013-10-15   \n",
       "\n",
       "                                      authors_parsed              cats_split  \\\n",
       "0  [['Balázs', 'C.', ''], ['Berger', 'E. L.', '']...              ['hep-ph']   \n",
       "1  [['Streinu', 'Ileana', ''], ['Theran', 'Louis'...    ['math.CO', 'cs.CG']   \n",
       "2                           [['Pan', 'Hongjun', '']]      ['physics.gen-ph']   \n",
       "3                          [['Callan', 'David', '']]             ['math.CO']   \n",
       "4  [['Abu-Shammala', 'Wael', ''], ['Torchinsky', ...  ['math.CA', 'math.FA']   \n",
       "\n",
       "  general_category  \n",
       "0         [hep-ph]  \n",
       "1       [math, cs]  \n",
       "2        [physics]  \n",
       "3           [math]  \n",
       "4     [math, math]  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_20k.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since machine learning models only accept numbers as an input, we need to convert words to numbers. There are many techniques for this task, and one of the simplest ones is to make a vector of abstract using **TF-IDF** method. The numeric representation of each word is proportional to frequency of the word in documents ([more about TF-IDF](https://en.wikipedia.org/wiki/Tf%E2%80%93idf))."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When abstracts are converted to numbers, we feed the the `abstract` as features and `general_category` as labels to the model for training. A simple model that is frequently use for text classification is Naive Bayes model. The Naive Bayes models predicts the category of an article based on prior knowledge of features of a class in training data. The limitation of Naive Bayes model is that is assumes features (in our case words) are not correlated, which might not be true for many cases. Despite this limitation, Naive Bayes is fast and can be used as strong base model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to evaluate the performance of our model, we need to select a suitable metric. In a classification problem, accuracy, precision and recall are the most common metrics. Since our dataset is imbalanced, accuracy will not be a good choice to measure the performance. Our goal is to accurately identify a label in our predictions (high precision), and also we want to identify most of the samples of a label (high recall). So we select f1-score as our metric, since it is a harmonic mean of the two previous metrics."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So the steps for the model training are:\n",
    "    \n",
    "1. Convert labels (`general_category`) to 0's and 1's\n",
    "2. Convert abstracts to numbers using TF-IDF\n",
    "3. Fit the model on training data\n",
    "4. Predict the f1-score on test data to calculate the evaluation metric"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better picture of model performance, we use K-fold validation technique to split training dataset into k parts. Then we repeat the above process for each fold of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above steps are implemented in `train.py` script in `src` directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's train our first model with 3 folds:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dir_path = os.path.dirname(os.getcwd())\n",
    "SRC_PATH = os.path.join(dir_path, \"src\")\n",
    "\n",
    "if SRC_PATH not in sys.path:\n",
    "    sys.path.append(SRC_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train, config_set\n",
    "from train import train_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/motare/works/codes/arxiv_interface/arxiv_venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/motare/works/codes/arxiv_interface/arxiv_venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.83      0.89      1403\n",
      "           1       0.86      0.77      0.82      1312\n",
      "           2       0.89      0.37      0.52       389\n",
      "           3       0.00      0.00      0.00         2\n",
      "           4       0.73      0.31      0.43       366\n",
      "           5       0.75      0.42      0.54       125\n",
      "           6       0.00      0.00      0.00        63\n",
      "           7       0.76      0.57      0.65       599\n",
      "           8       0.81      0.58      0.67       636\n",
      "           9       0.85      0.89      0.87      1658\n",
      "          10       1.00      0.01      0.01       284\n",
      "          11       0.00      0.00      0.00       141\n",
      "          12       0.00      0.00      0.00        92\n",
      "          13       0.80      0.02      0.04       189\n",
      "          14       0.64      0.02      0.03       554\n",
      "          15       1.00      0.02      0.04       112\n",
      "          16       0.00      0.00      0.00        33\n",
      "          17       0.95      0.33      0.49       451\n",
      "          18       0.00      0.00      0.00        69\n",
      "\n",
      "   micro avg       0.87      0.57      0.69      8478\n",
      "   macro avg       0.58      0.27      0.32      8478\n",
      "weighted avg       0.81      0.57      0.62      8478\n",
      " samples avg       0.68      0.64      0.64      8478\n",
      "\n",
      "f1_score: 0.31642732037063015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/motare/works/codes/arxiv_interface/arxiv_venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/motare/works/codes/arxiv_interface/arxiv_venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/motare/works/codes/arxiv_interface/arxiv_venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/motare/works/codes/arxiv_interface/arxiv_venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1570: UndefinedMetricWarning: F-score is ill-defined and being set to 0.0 in labels with no true nor predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, \"true nor predicted\", \"F-score is\", len(true_sum))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.95      0.84      0.89      1338\n",
      "           1       0.85      0.78      0.82      1266\n",
      "           2       0.87      0.40      0.55       250\n",
      "           3       0.00      0.00      0.00         0\n",
      "           4       0.74      0.28      0.41       372\n",
      "           5       0.91      0.42      0.57       195\n",
      "           6       0.00      0.00      0.00        81\n",
      "           7       0.70      0.62      0.66       629\n",
      "           8       0.82      0.57      0.67       679\n",
      "           9       0.85      0.90      0.87      1656\n",
      "          10       0.00      0.00      0.00       289\n",
      "          11       0.00      0.00      0.00       149\n",
      "          12       0.00      0.00      0.00        88\n",
      "          13       1.00      0.04      0.07       188\n",
      "          14       0.64      0.01      0.02       553\n",
      "          15       0.00      0.00      0.00       121\n",
      "          16       0.00      0.00      0.00        31\n",
      "          17       0.87      0.31      0.46       454\n",
      "          18       0.00      0.00      0.00        63\n",
      "\n",
      "   micro avg       0.85      0.57      0.69      8402\n",
      "   macro avg       0.48      0.27      0.32      8402\n",
      "weighted avg       0.76      0.57      0.62      8402\n",
      " samples avg       0.68      0.64      0.64      8402\n",
      "\n",
      "f1_score: 0.31578971092237645\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.96      0.84      0.89      1309\n",
      "           1       0.87      0.80      0.83      1348\n",
      "           2       0.82      0.35      0.49       338\n",
      "           3       0.00      0.00      0.00         1\n",
      "           4       0.81      0.29      0.43       371\n",
      "           5       0.85      0.47      0.61       196\n",
      "           6       0.00      0.00      0.00        72\n",
      "           7       0.71      0.59      0.65       654\n",
      "           8       0.77      0.58      0.66       592\n",
      "           9       0.85      0.88      0.86      1660\n",
      "          10       0.00      0.00      0.00       297\n",
      "          11       0.00      0.00      0.00       137\n",
      "          12       1.00      0.03      0.05        74\n",
      "          13       0.62      0.03      0.06       172\n",
      "          14       0.73      0.02      0.04       503\n",
      "          15       0.00      0.00      0.00       128\n",
      "          16       0.00      0.00      0.00        36\n",
      "          17       0.91      0.32      0.47       437\n",
      "          18       0.00      0.00      0.00       148\n",
      "\n",
      "   micro avg       0.85      0.57      0.68      8473\n",
      "   macro avg       0.52      0.27      0.32      8473\n",
      "weighted avg       0.76      0.57      0.62      8473\n",
      " samples avg       0.68      0.64      0.65      8473\n",
      "\n",
      "f1_score: 0.317889458166734\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/motare/works/codes/arxiv_interface/arxiv_venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/home/motare/works/codes/arxiv_interface/arxiv_venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "train_model(3, 'n_bayes') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The f1-score is around 0.31 which is not great. There are a few reasons that the performance is poor:\n",
    "- Number of samples for each category is not enough. (e.g category 3, 6, 12 and 16)\n",
    "- The features generated by TF-IDF technique are not a good representative of each category. There is a need for more elaborate feature engineering.\n",
    "- The Naive Bayes model is a simple model that is not powerful to make good predictions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To overcome the first reason, we load the second dataset with 100k samples, so there are more samples for each category. We postpone feature engineering of the TF-IDF technique to a later time, and we use more powerful transformer models in next section to compare the performance of newer models to Naive Bayes,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now let's load the second dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_df = pd.read_csv('../input/sample_df_2021.csv', converters={'general_category': pd.eval})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['physics']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_df['general_category'][1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import importlib\n",
    "importlib.reload(config_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/motare/works/codes/arxiv_interface/arxiv_venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.86      0.86      0.86      3039\n",
      "           1       0.74      0.78      0.76      3682\n",
      "           2       0.86      0.89      0.88     13847\n",
      "           3       0.67      0.01      0.02       401\n",
      "           4       0.55      0.52      0.53      2559\n",
      "           5       0.71      0.71      0.71      1140\n",
      "           6       0.50      0.60      0.55       576\n",
      "           7       0.93      0.07      0.13       196\n",
      "           8       0.68      0.78      0.73      1422\n",
      "           9       0.62      0.65      0.64      1393\n",
      "          10       0.84      0.83      0.83      9335\n",
      "          11       0.36      0.09      0.15       860\n",
      "          12       1.00      0.01      0.01       364\n",
      "          13       0.43      0.22      0.29       235\n",
      "          14       0.51      0.35      0.41       436\n",
      "          15       0.53      0.48      0.50      3516\n",
      "          16       0.63      0.06      0.11       606\n",
      "          17       0.85      0.14      0.24       406\n",
      "          18       0.79      0.56      0.66      1914\n",
      "          19       0.71      0.45      0.55      2452\n",
      "\n",
      "   micro avg       0.77      0.71      0.74     48379\n",
      "   macro avg       0.69      0.45      0.48     48379\n",
      "weighted avg       0.76      0.71      0.72     48379\n",
      " samples avg       0.78      0.78      0.75     48379\n",
      "\n",
      "f1_score: 0.47770746810028486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/motare/works/codes/arxiv_interface/arxiv_venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.85      0.85      0.85      2904\n",
      "           1       0.74      0.79      0.77      3584\n",
      "           2       0.87      0.89      0.88     13936\n",
      "           3       0.89      0.02      0.04       391\n",
      "           4       0.53      0.51      0.52      2546\n",
      "           5       0.69      0.70      0.70      1187\n",
      "           6       0.49      0.57      0.53       553\n",
      "           7       0.86      0.07      0.12       183\n",
      "           8       0.68      0.75      0.71      1403\n",
      "           9       0.66      0.66      0.66      1472\n",
      "          10       0.85      0.82      0.83      9356\n",
      "          11       0.37      0.09      0.14       911\n",
      "          12       1.00      0.01      0.02       385\n",
      "          13       0.55      0.21      0.31       238\n",
      "          14       0.56      0.37      0.45       429\n",
      "          15       0.55      0.48      0.51      3651\n",
      "          16       0.75      0.07      0.12       601\n",
      "          17       0.83      0.18      0.29       376\n",
      "          18       0.79      0.55      0.65      1944\n",
      "          19       0.68      0.47      0.56      2434\n",
      "\n",
      "   micro avg       0.77      0.71      0.74     48484\n",
      "   macro avg       0.71      0.45      0.48     48484\n",
      "weighted avg       0.76      0.71      0.72     48484\n",
      " samples avg       0.78      0.78      0.75     48484\n",
      "\n",
      "f1_score: 0.4824326760225971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/motare/works/codes/arxiv_interface/arxiv_venv/lib64/python3.9/site-packages/sklearn/metrics/_classification.py:1308: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in samples with no predicted labels. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85      2948\n",
      "           1       0.74      0.78      0.76      3681\n",
      "           2       0.86      0.89      0.88     13914\n",
      "           3       0.50      0.01      0.03       340\n",
      "           4       0.55      0.52      0.53      2545\n",
      "           5       0.71      0.71      0.71      1124\n",
      "           6       0.50      0.60      0.54       533\n",
      "           7       0.88      0.03      0.07       203\n",
      "           8       0.69      0.78      0.73      1369\n",
      "           9       0.63      0.66      0.64      1341\n",
      "          10       0.85      0.83      0.84      9301\n",
      "          11       0.40      0.09      0.15       851\n",
      "          12       0.33      0.00      0.01       343\n",
      "          13       0.49      0.19      0.27       247\n",
      "          14       0.52      0.33      0.40       439\n",
      "          15       0.53      0.48      0.50      3534\n",
      "          16       0.73      0.09      0.16       569\n",
      "          17       0.75      0.14      0.24       379\n",
      "          18       0.78      0.54      0.64      1947\n",
      "          19       0.68      0.46      0.55      2446\n",
      "\n",
      "   micro avg       0.77      0.71      0.74     48054\n",
      "   macro avg       0.65      0.45      0.48     48054\n",
      "weighted avg       0.75      0.71      0.72     48054\n",
      " samples avg       0.78      0.78      0.75     48054\n",
      "\n",
      "f1_score: 0.47507356645554777\n"
     ]
    }
   ],
   "source": [
    "train_model(3, 'n_bayes') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems that we got a better model since the f1-score improved to 0.47. But still there is room for more improvement. We can continue the model training stage with trying more models, feature engineering, model hyper-parameter optimization, number of features, samples per category, and different word embeddings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally we save the Naive Base as our baseline model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's predict the class of two samples using our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "# source: https://arxiv.org/pdf/2112.00728, category:math\n",
    "Sample1 = '''\n",
    "we address the problem of reshaping light in the schrödinger optics regime from the\n",
    "perspective of optimal control theoryN in technological applicationsL schrödinger optics is often\n",
    "used to model a slowlyMvarying amplitude of a paraMaxially propagating electric field where the\n",
    "square of the waveguideGs index of refraction is treated as the potentialN the objective of the\n",
    "optimal control problem is to find the controlling potential whichL together with the constraining\n",
    "schrödinger dynamicsL optimally reshape the intensity distribution of schrödinger eigenfunctions\n",
    "from one end of the waveguide to the otherN this work considers reshaping problems found\n",
    "in work due to kunkel and legerL and addresses computational needs by adopting tools from\n",
    "the quantum control literatureN the success of the optimal control approach is demonstrated\n",
    "numerically.\n",
    "'''\n",
    "\n",
    "# source: https://arxiv.org/pdf/2112.00746, category:hep-th\n",
    "Sample2 = '''\n",
    "We study quantum fields on an arbitrary, rigid background with boundary. We derive\n",
    "the action for a scalar in the holographic basis that separates the boundary and bulk de-\n",
    "grees of freedom. From this holographic action, a relation between Dirichlet and Neumann\n",
    "propagators valid for any background is obtained. As an application in a warped back-\n",
    "ground, we derive an exact formula for the flux of bulk modes emitted from the boundary.\n",
    "We also derive the holographic action in the presence of two boundaries. Integrating out\n",
    "free bulk modes, we derive a formula for the Casimir pressure on a (d−1)-brane depending\n",
    "only on the boundary-to-bulk propagators. In AdS2 we find that the quantum force pushes\n",
    "a point particle toward the AdS2 boundary. In higher dimensional AdSd+1 the quantum\n",
    "pressure amounts to a detuning of the brane tension, which gets renormalized for even d.\n",
    "We evaluate the one-loop boundary effective action in the presence of interactions by\n",
    "means of the heat kernel expansion. We integrate out a heavy scalar fluctuation with scalar\n",
    "interactions in AdSd+1, obtaining the long-distance effective Lagrangian encoding loop-\n",
    "generated boundary-localized operators. We integrate out nonabelian vector fluctuations\n",
    "in AdS4,5,6 and obtain the associated holographic Yang-Mills β functions. Turning to the\n",
    "expanding patch of dS, following recent proposals, we provide a boundary effective action\n",
    "generating the perturbative cosmological correlators by analytically continuing from dS to\n",
    "EAdS. We obtain the “cosmological” heat kernel coefficients in the scalar case and work\n",
    "out the divergent part of the dS4 effective action which renormalizes the cosmological\n",
    "correlators. More developments are needed to extract all one-loop information from the\n",
    "cosmological effective action.\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# STEPS\n",
    "# load model\n",
    "# load vectorizer\n",
    "# predict the category"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loading the trained model and vectorizer\n",
    "model_bin = open(config.MODEL_OUTPUT_PATH, 'rb') \n",
    "classifier = joblib.load(model_bin)\n",
    "\n",
    "vectorizer_bin = open(config.VECTORIZER_PATH, 'rb') \n",
    "vectorizer = joblib.load(vectorizer_bin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aa', 'ab', 'ab initio', ..., 'zeros', 'zeta', 'zone'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_str = vectorizer.transform([Sample1, Sample2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<2x5000 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 133 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions = classifier.predict(input_str)\n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0,  1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15, 16,\n",
       "       17, 18, 19])"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "classifier.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.0107416 , 0.02031755, 0.3593347 , 0.00967294, 0.0906358 ,\n",
       "        0.00963807, 0.00978814, 0.00893255, 0.00833041, 0.00673122,\n",
       "        0.00551098, 0.00664394, 0.01496101, 0.00934039, 0.01150463,\n",
       "        0.16272638, 0.01251457, 0.0135098 , 0.05720226, 0.00455834],\n",
       "       [0.02260705, 0.02337614, 0.00987463, 0.01550031, 0.00341146,\n",
       "        0.13106048, 0.00800314, 0.02474755, 0.03461081, 0.20197394,\n",
       "        0.06220145, 0.08799639, 0.02911355, 0.01423868, 0.03047882,\n",
       "        0.0576527 , 0.01702609, 0.01567191, 0.02728399, 0.0027305 ]])"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "probs=classifier.predict_proba(input_str)\n",
    "probs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier predicts none of the categories for the two samples, which in this case might be from poor performance of the trained model."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "arxiv_venv",
   "language": "python",
   "name": "arxiv_venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
